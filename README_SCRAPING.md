# ğŸ•·ï¸ Sistema de Scraping e Admin - Guia Completo

## ğŸ“‹ O que foi implementado

### âœ… 1. Schema do Banco Atualizado
- Campos adicionados: `banca`, `ano`, `orgao`, `origem`, `hash_enunciado`
- Tabela `admins` para controle de acesso administrativo

### âœ… 2. Sistema de Scraping (`scraper_questoes.py`)
- **AdaptaÃ§Ã£o automÃ¡tica de textos** para evitar direitos autorais
- **DetecÃ§Ã£o de duplicatas** via hash do enunciado
- **ExtraÃ§Ã£o de metadados**: banca, ano, Ã³rgÃ£o, cargo
- **Suporte a mÃºltiplas fontes**: URLs, HTML bruto, PDFs convertidos

### âœ… 3. Painel Admin no App
- **Adicionar/Editar conteÃºdo teÃ³rico** por questÃ£o
- **Gerenciar questÃµes**: visualizar, filtrar, deletar
- **Executar scraping** diretamente pela interface
- **ConfiguraÃ§Ãµes**: tornar usuÃ¡rios admin

### âœ… 4. DetecÃ§Ã£o e RemoÃ§Ã£o de Duplicatas
- Identifica questÃµes manuais duplicadas
- Remove automaticamente mantendo versÃµes do scraping

---

## ğŸš€ Como Usar

### Passo 1: Atualizar o Banco
```bash
python database.py
```

### Passo 2: Criar um Admin
```bash
python criar_admin.py
```
Isso torna o primeiro usuÃ¡rio cadastrado em admin.

**OU** faÃ§a login no app e use a aba "ConfiguraÃ§Ãµes" do painel admin para tornar outros usuÃ¡rios admin.

### Passo 3: Acessar o Painel Admin
1. FaÃ§a login no app (`streamlit run app_web.py`)
2. Clique em **"Acessar Admin"** na sidebar
3. VocÃª terÃ¡ acesso a 4 abas:
   - **ğŸ“ ConteÃºdo TeÃ³rico**: Adicionar explicaÃ§Ãµes Ã s questÃµes
   - **ğŸ” Gerenciar QuestÃµes**: Ver estatÃ­sticas, filtrar, deletar
   - **ğŸ•·ï¸ Scraping**: Executar scraping de URLs
   - **âš™ï¸ ConfiguraÃ§Ãµes**: Gerenciar admins

---

## ğŸ•·ï¸ Como Usar o Scraping

### OpÃ§Ã£o 1: Via Interface Web (Recomendado)
1. Acesse o **Painel Admin** â†’ aba **"Scraping"**
2. Cole as URLs das questÃµes (uma por linha)
3. Selecione o cargo (opcional)
4. Clique em **"Executar Scraping"**

### OpÃ§Ã£o 2: Via Script Python
```python
from scraper_questoes import ScraperQuestoes

scraper = ScraperQuestoes()

# Lista de URLs para processar
urls = [
    "https://exemplo.com/questao1",
    "https://exemplo.com/questao2",
]

# Processar (cargo_id Ã© opcional)
sucesso, erros, duplicatas = scraper.processar_urls(
    urls, 
    cargo_id=1,  # ID do cargo ou None
    delay=2  # Delay entre requisiÃ§Ãµes (segundos)
)

print(f"âœ… {sucesso} salvas | âŒ {erros} erros | ğŸ”„ {duplicatas} duplicatas")
```

### OpÃ§Ã£o 3: Processar HTML/Texto Bruto
```python
html_texto = """
1. Qual Ã© a capital do Brasil?
A) SÃ£o Paulo
B) Rio de Janeiro
C) BrasÃ­lia
D) Belo Horizonte
"""

questoes = scraper.extrair_de_texto_bruto(
    html_texto,
    banca="CESPE",
    ano=2024,
    orgao="IBGE",
    materia="Geografia"
)

for q in questoes:
    scraper.salvar_questao(q, cargo_id=1)
```

---

## ğŸ§¹ Limpeza de Duplicatas

### Gerar Hash para QuestÃµes Antigas
```python
scraper = ScraperQuestoes()
scraper.marcar_questoes_manuais_para_remocao()
```

### Remover Duplicatas
```python
scraper.remover_duplicatas_manuais()
```

**OU** use o botÃ£o **"Remover QuestÃµes Manuais Duplicadas"** no painel admin.

---

## ğŸ“ Adicionar ConteÃºdo TeÃ³rico

1. Acesse **Painel Admin** â†’ **"ConteÃºdo TeÃ³rico"**
2. Selecione a questÃ£o pelo ID ou enunciado
3. Digite a explicaÃ§Ã£o teÃ³rica (suporta **negrito** com `**texto**`)
4. Clique em **"Salvar ConteÃºdo TeÃ³rico"**

O conteÃºdo aparecerÃ¡ automaticamente no modo revisÃ£o dos simulados!

---

## ğŸ”§ AdaptaÃ§Ã£o de Textos (Anti-Direitos Autorais)

O sistema adapta automaticamente os textos usando:
- **SubstituiÃ§Ãµes de sinÃ´nimos**: "de acordo com" â†’ "conforme"
- **VariaÃ§Ãµes de linguagem**: "assinale" â†’ "marque"
- **ReformulaÃ§Ã£o**: mantÃ©m o sentido, muda a forma
- **Hash para detecÃ§Ã£o**: evita duplicatas mesmo com adaptaÃ§Ã£o

**Importante**: A adaptaÃ§Ã£o Ã© automÃ¡tica, mas vocÃª pode revisar manualmente no painel admin.

---

## ğŸ“Š Estrutura de Dados

Cada questÃ£o agora possui:
- `enunciado`: Texto da questÃ£o (adaptado)
- `op_a` a `op_e`: Alternativas (adaptadas)
- `correta`: Letra da resposta correta
- `materia`: MatÃ©ria/disciplina
- `banca`: CESPE, FGV, VUNESP, etc.
- `ano`: Ano da prova
- `orgao`: Ã“rgÃ£o/instituiÃ§Ã£o
- `origem`: "manual" ou "scraping"
- `hash_enunciado`: Hash para detecÃ§Ã£o de duplicatas
- `explicacao_teorica`: ConteÃºdo teÃ³rico (editÃ¡vel pelo admin)

---

## âš ï¸ Importante

1. **Respeite os termos de uso** dos sites que vocÃª estÃ¡ fazendo scraping
2. **Use delays** entre requisiÃ§Ãµes para nÃ£o sobrecarregar servidores
3. **Revise as questÃµes** coletadas antes de publicar
4. **AdaptaÃ§Ã£o automÃ¡tica** ajuda, mas nÃ£o substitui revisÃ£o manual
5. **ConteÃºdo teÃ³rico** deve ser adicionado manualmente por professores/admin

---

## ğŸ¯ PrÃ³ximos Passos Sugeridos

- Integrar com APIs de bancas (quando disponÃ­veis)
- Sistema de OCR para PDFs de provas
- Machine Learning para melhorar adaptaÃ§Ã£o de textos
- ExportaÃ§Ã£o de questÃµes em formatos padrÃ£o (QTI, etc.)
- Sistema de tags e categorizaÃ§Ã£o automÃ¡tica
